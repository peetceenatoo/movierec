{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMPORT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f'./Datasets/dataset.csv'\n",
    "\n",
    "with open(dataset_path, 'rt') as f:\n",
    "    df = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FILTER FUNCTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the filter function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] \"Movies included in the array are those whose even one attribute value matches with the input value of the user.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter(movies_df, minRating=0, maxRating=10, minYear=0, maxYear=math.inf, genres=[], directors=[], authors=[]):\n",
    "\n",
    "    # Take the movies which are in the range of the rating\n",
    "    rating_df = movies_df[movies_df['averageRating'] >= minRating]\n",
    "    rating_df = rating_df[rating_df['averageRating'] <= maxRating]\n",
    "\n",
    "    # Take the movies which are in the range of the year\n",
    "    year_df = movies_df[movies_df['startYear'] >= minYear]\n",
    "    year_df = year_df[year_df['startYear'] <= maxYear]\n",
    "\n",
    "    # Take the movies from the movies_df such that genres list is contained in the list of comma-separated values in movies_df['genres']\n",
    "    if genres:\n",
    "        genres_df = movies_df[movies_df['genres'].apply(lambda x: all(g in x for g in genres))]\n",
    "\n",
    "    # Take the movies from the movies_df such that directors list is contained in the list of comma-separated values in movies_df['directors']\n",
    "    if directors:\n",
    "        directors_df = movies_df[movies_df['directors'].apply(lambda x: all(d in x for d in directors))]\n",
    "\n",
    "    # Take the movies from the movies_df such that authors list is contained in the list of comma-separated values in movies_df['authors']\n",
    "    if authors:\n",
    "        authors_df = movies_df[movies_df['authors'].apply(lambda x: all(a in x for a in authors))]\n",
    "\n",
    "    # Take the union of all the dataframes avoiding duplicates\n",
    "    filtered_df = pd.concat([rating_df, year_df, genres_df, directors_df, authors_df]).drop_duplicates() # [1]\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RECOMMENDER FUNCTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the recommender function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] \"In our research we have also found that generally a user prefer a list with five movies so we assume K equal to be 4 so that an average every K has five movies, where K is the number of cluster to be formed.\"\n",
    "\n",
    "[2] \"For each cluster k1, k2 , k3, k4 we assume initial centroid c1, c2, c3, c4 which corresponds to the first, sixth, eleventh, and sixteenth movie in the movie array.\"\n",
    "\n",
    "[3] \"The distance measure we have used to calculate the distance between data points and centroid is the Euclidean Distance.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[A] One-hot encoding for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MovieREC(movies_df, n_clusters=4): # [1]\n",
    "\n",
    "    #  ---- Filtering top 20 movies with highest average rating ---- #\n",
    " \n",
    "    # Return an empty list if the input list is empty\n",
    "    if len(movies_df) == 0:\n",
    "        return list()\n",
    "    \n",
    "    # Resize the number of clusters based on the number of movies in the input list if there are less than 20 movies\n",
    "    # Otherwise keep the 20 movies with highest average rating, giving priority by number of ratings\n",
    "    if len(movies_df) < 20:\n",
    "        n_clusters = math.ceil(n_clusters * (len(movies_df)/20)) \n",
    "    else:\n",
    "        movies_df = movies_df.sort_values(by=['avg_rating', 'num_ratings'], ascending=False).head(20)\n",
    "\n",
    "    # Drop column num_ratings\n",
    "    movies_df = movies_df.drop(columns=['num_ratings'])\n",
    "\n",
    "    # ---- K-Means Clustering Initialization ---- #\n",
    "\n",
    "    # Create a dictionary which assigns to each column index in movie_df their name (averageRating, startYear, genres, directors, authors)\n",
    "    col_names = {i: movies_df.columns[i] for i in range(2, 7)}\n",
    "\n",
    "    # Now let us create a matrix with num_clusers rows and one column for each column in (averageRating, startYear, genres, directors, authors)\n",
    "    # Pick evenly spaced n_clusters indeces from the list of movies, starting from the index 0, up to len-1\n",
    "    centroids_indexes = [math.floor(i * len(movies_df)/n_clusters) for i in range(n_clusters)] # [2]\n",
    "    # Store for each centroid (movie) the values of its corresponding columns in the movies_df for averageRating and startYear\n",
    "    centroids = [[movies_df[col_names[i]][centroids_indexes[j]] for i in range(2)] for j in range(n_clusters)]\n",
    "    # And append to each centroid (movie) a dictionary which assigns 1 to the values in the corresponding list, for genres, directors and authors\n",
    "    for j in range(n_clusters):\n",
    "        centroids[j].append( {movies_df[col_names[i]][centroids_indexes[j]]: 1 for i in range(2, len(movies_df.columns))} ) # [A]\n",
    "\n",
    "    # ---- K-Means Algorithm ---- #\n",
    "        \n",
    "    # Initialize to True a \"changing\" flag, which will be set to False when the centroids stop changing\n",
    "    changing = True\n",
    "\n",
    "    # While the centroids keep changing...\n",
    "    while changing:\n",
    "\n",
    "        # Set the \"changing\" flag to False\n",
    "        changing = False\n",
    "\n",
    "        # Store a copy of the previous centroids\n",
    "        prev_centroids = centroids.copy()\n",
    "\n",
    "        # Create a list of clusters, where each cluster is the list of indexes of the movies in the movies_df\n",
    "        clusters = [[] for i in range(n_clusters)]\n",
    "\n",
    "        # Now, for each movie in the movies_df...\n",
    "        for i in range(len(movies_df)):\n",
    "\n",
    "            # If i is in the centroids_indexes, add it to the corresponding cluster\n",
    "            if i in centroids_indexes:\n",
    "                clusters[centroids_indexes.index(i)].append(i)\n",
    "                continue\n",
    "\n",
    "            # Save a tuple (math.inf, -1) to store the minimum distance and the index of the closest centroid\n",
    "            min_distance = (math.inf, -1)\n",
    "\n",
    "            # And compute the closest centroid for the movie i\n",
    "            for c_idx in centroids_indexes:\n",
    "\n",
    "                # Init the one-dimension distances list\n",
    "                tempDistances = []\n",
    "\n",
    "                # Compute the 1D distances for the averageRating and startYear columns\n",
    "                for j in range(2):\n",
    "                    tempDistances.append(movies_df[col_names[j]][i] - centroids[c_idx][j])\n",
    "\n",
    "                # Compute the 1D one-hot tempDistance for genres, directors and authors as well\n",
    "                for j in range(2, len(movies_df.columns)):\n",
    "\n",
    "                    # By summing 1 for each value in movies_df[col_names[j]][i] not in centroids[c_idx][j].keys()\n",
    "                    tempBoth = sum([1 for x in movies_df[col_names[j]][i] if x not in centroids[c_idx][j].keys()])\n",
    "                    # Summing (1 - centroids[c_idx][j][x]) for each x both in movies_df[col_names[j]][i] and in centroids[c_idx][j].keys()\n",
    "                    tempMovie = sum([1 - centroids[c_idx][j][x] for x in movies_df[col_names[j]][i] if x in centroids[c_idx][j].keys()])\n",
    "                    # Summing centroids[c_idx][j][x] for each x in centroids[c_idx][j].keys() and not in movies_df[col_names[j]][i]\n",
    "                    tempCentroid = sum([centroids[c_idx][j][x] for x in centroids[c_idx][j].keys() if x not in movies_df[col_names[j]][i]])\n",
    "\n",
    "                    # And then appending the overall sum to the 1D distances list\n",
    "                    tempDistances.append(tempBoth + tempMovie + tempCentroid)\n",
    "\n",
    "                # Compute the Euclidean distance between the movie i and the centroid c_idx\n",
    "                distance = math.sqrt(sum([x**2 for x in tempDistances])) # [3]\n",
    "                                    \n",
    "                # If the distance is less than the minimum distance, update the minimum distance and the index of the closest centroid\n",
    "                if distance < min_distance[0]:\n",
    "                    min_distance = (distance, c_idx)\n",
    "\n",
    "            # To finally add the movie i to the cluster of the closest centroid\n",
    "            clusters[min_distance[1]].append(i)\n",
    "\n",
    "        # Now set the \"changing\" flag to True if clusters have changed\n",
    "        for i in range(n_clusters):\n",
    "            if set(clusters[i]) != set(prev_centroids[i]):\n",
    "                changing = True\n",
    "                break\n",
    "\n",
    "        # If they did not change, K-Means has converged and we can stop\n",
    "\n",
    "    # ---- Pick best cluster ---- #\n",
    "            \n",
    "    clusters_dict = {}\n",
    "\n",
    "    # Compute the weighted average movie rating for each cluster\n",
    "    # Each cluster contains at least one movie with non-zero weight, so we can safely compute the weighted average\n",
    "    for cl in clusters:\n",
    "        weights_sum = 0\n",
    "        weighted_sum = 0\n",
    "        for i in cl:\n",
    "            weights_sum += movies_df['weight'][i]\n",
    "            weighted_sum += movies_df['averageRating'][i] * movies_df['weight'][i]\n",
    "        clusters_dict[cl] = weighted_sum/weights_sum\n",
    "\n",
    "    # Return the cluster with the highest weighted average movie rating\n",
    "    return clusters[max(clusters_dict, key=clusters_dict.get)] # max() returns the first key with the highest value\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
